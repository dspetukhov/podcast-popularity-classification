{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee3ecb6-40ea-46d7-9568-fcb2fabd92e0",
   "metadata": {},
   "source": [
    "**Model training in three ways:**\n",
    "\n",
    "- using images obtained with `LFCC` in `09_preprocessing_lfcc.ipynb`\n",
    "- using spectrograms transformed by `LFCC` on the fly\n",
    "- using spectrograms transformed by `LFCC` on the fly with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ebc71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T07:52:20.075814Z",
     "start_time": "2024-03-17T07:52:13.517889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "#\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "#\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ConvertImageDtype\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53825dce-2bd1-425f-b04f-339a61d7430d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "2.3.0+cu121\n",
      "0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1aa607c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.048903Z",
     "start_time": "2024-01-07T09:39:43.045946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_path = 'data/raw/'\n",
    "data_path = 'data/lfcc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc893f9-4806-4e31-bbad-8187909d66cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9771b003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.895828Z",
     "start_time": "2024-01-07T09:39:43.699453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = yaml.safe_load(open('labels.yaml'))[2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de3b0d9-8bbd-4110-bade-aa843d8de608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = zip(*labels.items())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4130ef6d-d8f8-45d4-aa12-fd8f9d34aaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.train()\n",
    "    for X, Y in dataloader:\n",
    "        X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "        #\n",
    "        output = model(X)\n",
    "        loss = criterion(output.view(1), Y)\n",
    "        #\n",
    "        losses.append(loss.item())\n",
    "        y_true.append(Y.item())\n",
    "        y_score.append(torch.sigmoid(output).item())\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)\n",
    "\n",
    "\n",
    "def testing(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "            #\n",
    "            output = model(X)\n",
    "            loss = criterion(output.view(1), Y)\n",
    "            #\n",
    "            losses.append(loss.item())\n",
    "            y_true.append(Y.item())\n",
    "            y_score.append(torch.sigmoid(output).item())\n",
    "    #\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e3ccb",
   "metadata": {},
   "source": [
    "# Modelling using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d155c4-6487-404d-8ecc-3520e29783f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e5562e-7440-44b6-8418-ad87747370ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1121af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.cid = ConvertImageDtype(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        image = read_image(f'{data_path}/{episode}.png')\n",
    "        return self.cid(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0458835e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409bad50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324496c0-4ba0-496f-8474-142cbb8d4f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(2, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 4))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(3, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(5, 10)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(5, 10))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(200, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shapes = [x.shape]\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # shapes.append(x.shape)\n",
    "        #\n",
    "        print(shapes)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print(x.shape, self.training)\n",
    "        #\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c12eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7f6d1-d7a3-4068-8298-498cc806105b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbef7242-695b-442a-8ae5-a6437bc54af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '10_lfcc_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7767851-cb54-4048-b11e-640c6cba4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm artifacts/10_lfcc_images.joblib\n",
    "# !rm artifacts/10_lfcc_images.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db1ed50-2f25-461f-b04f-5dc6827f3750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b1d817-b5d5-4d1e-8bb0-be84cf3b52f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc0f007270345ca86db2df2cda228c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5e3b2cf9-d500-4d83-9e78-be372e64baa0',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': '20b84428-f359-4b48-ac37-f245f8254328',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ab33a492-064a-4c29-8021-a866cb15e4f7',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2c73c767-db48-47ae-b1dd-8a50f29e2645',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c137a9-37e8-4ebf-a878-5d640d106514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6676 | Testing loss: 0.5911 | Training AUC: 0.5438 | Testing AUC: 0.6917\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6433 | Testing loss: 0.5823 | Training AUC: 0.3953 | Testing AUC: 0.6992\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6111 | Testing loss: 0.6061 | Training AUC: 0.5057 | Testing AUC: 0.6917\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.5888 | Testing loss: 0.6063 | Training AUC: 0.5893 | Testing AUC: 0.7293\n",
      "==============================================================================-------------------------"
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c8157-7ab9-4970-ad55-2f941d85349d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling `as is`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "467333f7-40e4-4e4e-b799-54a0a55b6bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bfc3ee3-d6d9-4801-9295-898f5822d4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ca6a35-bd61-437b-b66d-6438e2fad0d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        #\n",
    "        return get_spectrogram(waveform.mean(dim=0), sample_rate, 'lfcc'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0dbd68-6737-4dc1-a49b-fd38127b72e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ff78e2-ab51-4167-ba7b-a13ae54dafbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3e2b10a-ebce-40b0-8c06-0c44ea498a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 4))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 10)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(5, 10))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(50, 8)\n",
    "        self.linear2 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shapes = [x.shape]\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(shapes, self.training)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6d51325-4dec-43e8-bf38-bcb6daeeb5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "975906ab-b7d6-4963-b7f6-7eea79da2334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 40, 4021]), torch.Size([1, 19, 1004]), torch.Size([1, 5, 166])] True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 40, 462]), torch.Size([1, 19, 114]), torch.Size([1, 5, 18])] True\n",
      "[torch.Size([1, 40, 673]), torch.Size([1, 19, 167]), torch.Size([1, 5, 27])] True\n",
      "[torch.Size([1, 40, 376]), torch.Size([1, 19, 93]), torch.Size([1, 5, 14])] True\n",
      "[torch.Size([1, 40, 14776]), torch.Size([1, 19, 3693]), torch.Size([1, 5, 614])] True\n",
      "[torch.Size([1, 40, 379]), torch.Size([1, 19, 94]), torch.Size([1, 5, 14])] True\n",
      "[torch.Size([1, 40, 10663]), torch.Size([1, 19, 2665]), torch.Size([1, 5, 443])] True\n",
      "[torch.Size([1, 40, 6260]), torch.Size([1, 19, 1564]), torch.Size([1, 5, 259])] True\n",
      "[torch.Size([1, 40, 4136]), torch.Size([1, 19, 1033]), torch.Size([1, 5, 171])] True\n",
      "[torch.Size([1, 40, 571]), torch.Size([1, 19, 142]), torch.Size([1, 5, 22])] True\n",
      "[torch.Size([1, 40, 576]), torch.Size([1, 19, 143]), torch.Size([1, 5, 23])] True\n",
      "[torch.Size([1, 40, 819]), torch.Size([1, 19, 204]), torch.Size([1, 5, 33])] True\n",
      "[torch.Size([1, 40, 6710]), torch.Size([1, 19, 1676]), torch.Size([1, 5, 278])] True\n",
      "[torch.Size([1, 40, 8820]), torch.Size([1, 19, 2204]), torch.Size([1, 5, 366])] True\n",
      "[torch.Size([1, 40, 7674]), torch.Size([1, 19, 1917]), torch.Size([1, 5, 318])] True\n",
      "[torch.Size([1, 40, 595]), torch.Size([1, 19, 148]), torch.Size([1, 5, 23])] True\n",
      "[torch.Size([1, 40, 8783]), torch.Size([1, 19, 2195]), torch.Size([1, 5, 365])] True\n",
      "[torch.Size([1, 40, 9611]), torch.Size([1, 19, 2402]), torch.Size([1, 5, 399])] True\n",
      "[torch.Size([1, 40, 9786]), torch.Size([1, 19, 2445]), torch.Size([1, 5, 406])] True\n",
      "[torch.Size([1, 40, 9065]), torch.Size([1, 19, 2265]), torch.Size([1, 5, 376])] True\n",
      "[torch.Size([1, 40, 380]), torch.Size([1, 19, 94]), torch.Size([1, 5, 14])] True\n",
      "[torch.Size([1, 40, 6836]), torch.Size([1, 19, 1708]), torch.Size([1, 5, 283])] True\n",
      "[torch.Size([1, 40, 9596]), torch.Size([1, 19, 2398]), torch.Size([1, 5, 398])] True\n",
      "[torch.Size([1, 40, 439]), torch.Size([1, 19, 109]), torch.Size([1, 5, 17])] True\n",
      "[torch.Size([1, 40, 7519]), torch.Size([1, 19, 1879]), torch.Size([1, 5, 312])] True\n",
      "[torch.Size([1, 40, 5888]), torch.Size([1, 19, 1471]), torch.Size([1, 5, 244])] True\n",
      "[torch.Size([1, 40, 376]), torch.Size([1, 19, 93]), torch.Size([1, 5, 14])] True\n",
      "[torch.Size([1, 40, 10717]), torch.Size([1, 19, 2678]), torch.Size([1, 5, 445])] True\n",
      "[torch.Size([1, 40, 8889]), torch.Size([1, 19, 2221]), torch.Size([1, 5, 369])] True\n",
      "[torch.Size([1, 40, 7932]), torch.Size([1, 19, 1982]), torch.Size([1, 5, 329])] True\n",
      "[torch.Size([1, 40, 8442]), torch.Size([1, 19, 2109]), torch.Size([1, 5, 350])] True\n",
      "[torch.Size([1, 40, 811]), torch.Size([1, 19, 202]), torch.Size([1, 5, 32])] True\n",
      "[torch.Size([1, 40, 558]), torch.Size([1, 19, 138]), torch.Size([1, 5, 22])] True\n",
      "[torch.Size([1, 40, 6416]), torch.Size([1, 19, 1603]), torch.Size([1, 5, 266])] True\n",
      "[torch.Size([1, 40, 391]), torch.Size([1, 19, 97]), torch.Size([1, 5, 15])] True\n",
      "[torch.Size([1, 40, 702]), torch.Size([1, 19, 174]), torch.Size([1, 5, 28])] True\n",
      "[torch.Size([1, 40, 9530]), torch.Size([1, 19, 2381]), torch.Size([1, 5, 396])] True\n",
      "[torch.Size([1, 40, 8592]), torch.Size([1, 19, 2147]), torch.Size([1, 5, 357])] True\n",
      "[torch.Size([1, 40, 473]), torch.Size([1, 19, 117]), torch.Size([1, 5, 18])] True\n",
      "[torch.Size([1, 40, 10179]), torch.Size([1, 19, 2544]), torch.Size([1, 5, 423])] True\n",
      "[torch.Size([1, 40, 1385]), torch.Size([1, 19, 345]), torch.Size([1, 5, 56])] True\n",
      "[torch.Size([1, 40, 9316]), torch.Size([1, 19, 2328]), torch.Size([1, 5, 387])] True\n",
      "[torch.Size([1, 40, 662]), torch.Size([1, 19, 164]), torch.Size([1, 5, 26])] True\n",
      "[torch.Size([1, 40, 419]), torch.Size([1, 19, 104]), torch.Size([1, 5, 16])] True\n",
      "[torch.Size([1, 40, 623]), torch.Size([1, 19, 155]), torch.Size([1, 5, 25])] True\n",
      "[torch.Size([1, 40, 12836]), torch.Size([1, 19, 3208]), torch.Size([1, 5, 533])] True\n",
      "[torch.Size([1, 40, 649]), torch.Size([1, 19, 161]), torch.Size([1, 5, 26])] True\n",
      "[torch.Size([1, 40, 7814]), torch.Size([1, 19, 1952]), torch.Size([1, 5, 324])] True\n",
      "[torch.Size([1, 40, 8887]), torch.Size([1, 19, 2221]), torch.Size([1, 5, 369])] True\n",
      "[torch.Size([1, 40, 9798]), torch.Size([1, 19, 2448]), torch.Size([1, 5, 407])] True\n",
      "[torch.Size([1, 40, 434]), torch.Size([1, 19, 107]), torch.Size([1, 5, 17])] True\n",
      "[torch.Size([1, 40, 5070]), torch.Size([1, 19, 1266]), torch.Size([1, 5, 210])] True\n",
      "[torch.Size([1, 40, 402]), torch.Size([1, 19, 99]), torch.Size([1, 5, 15])] True\n",
      "[torch.Size([1, 40, 369]), torch.Size([1, 19, 91]), torch.Size([1, 5, 14])] True\n",
      "[torch.Size([1, 40, 643]), torch.Size([1, 19, 160]), torch.Size([1, 5, 25])] True\n",
      "[torch.Size([1, 40, 5436]), torch.Size([1, 19, 1358]), torch.Size([1, 5, 225])] True\n",
      "[torch.Size([1, 40, 7198]), torch.Size([1, 19, 1798]), torch.Size([1, 5, 298])] True\n",
      "[torch.Size([1, 40, 669]), torch.Size([1, 19, 166]), torch.Size([1, 5, 26])] True\n",
      "[torch.Size([1, 40, 6606]), torch.Size([1, 19, 1650]), torch.Size([1, 5, 274])] True\n",
      "[torch.Size([1, 40, 813]), torch.Size([1, 19, 202]), torch.Size([1, 5, 32])] True\n",
      "[torch.Size([1, 40, 6570]), torch.Size([1, 19, 1641]), torch.Size([1, 5, 272])] True\n",
      "[torch.Size([1, 40, 853]), torch.Size([1, 19, 212]), torch.Size([1, 5, 34])] True\n",
      "[torch.Size([1, 40, 10327]), torch.Size([1, 19, 2581]), torch.Size([1, 5, 429])] True\n",
      "[torch.Size([1, 40, 8593]), torch.Size([1, 19, 2147]), torch.Size([1, 5, 357])] True\n",
      "[torch.Size([1, 40, 289]), torch.Size([1, 19, 71]), torch.Size([1, 5, 11])] True\n",
      "[torch.Size([1, 40, 690]), torch.Size([1, 19, 171]), torch.Size([1, 5, 27])] True\n",
      "[torch.Size([1, 40, 6543]), torch.Size([1, 19, 1635]), torch.Size([1, 5, 271])] True\n",
      "[torch.Size([1, 40, 389]), torch.Size([1, 19, 96]), torch.Size([1, 5, 15])] True\n",
      "[torch.Size([1, 40, 633]), torch.Size([1, 19, 157]), torch.Size([1, 5, 25])] True\n",
      "[torch.Size([1, 40, 424]), torch.Size([1, 19, 105]), torch.Size([1, 5, 16])] True\n",
      "[torch.Size([1, 40, 2304]), torch.Size([1, 19, 575]), torch.Size([1, 5, 95])] True\n",
      "[torch.Size([1, 40, 10032]), torch.Size([1, 19, 2507]), torch.Size([1, 5, 417])] True\n",
      "[torch.Size([1, 40, 8935]), torch.Size([1, 19, 2233]), torch.Size([1, 5, 371])] True\n",
      "[torch.Size([1, 40, 435]), torch.Size([1, 19, 108]), torch.Size([1, 5, 17])] True\n",
      "[torch.Size([1, 40, 9916]), torch.Size([1, 19, 2478]), torch.Size([1, 5, 412])] True\n",
      "[torch.Size([1, 40, 299]), torch.Size([1, 19, 74]), torch.Size([1, 5, 11])] True\n",
      "[torch.Size([1, 40, 535]), torch.Size([1, 19, 133]), torch.Size([1, 5, 21])] True\n",
      "[torch.Size([1, 40, 6391]), torch.Size([1, 19, 1597]), torch.Size([1, 5, 265])] True\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96b5a5-3a03-4d5c-8cb9-3bf0e0ed6d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019e2982-65f6-4d2f-b2fe-4f3a6e8cdf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '10_lfcc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65af4d7-a2a5-4631-8ad3-440111cc8240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm artifacts/10_lfcc.joblib\n",
    "# !rm artifacts/10_lfcc.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9face793-f709-4a49-a1a7-e8e68df32306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00b9f53-20cf-4b24-a127-440f33a78386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315e6def7b0458aa96f3b99664c3a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd75c8fd7-84f7-4255-93c1-d86de94902d8',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a67c2412-66fe-4a2c-9ea1-250839a17e70',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1f4a53af-c8a9-433e-9b94-19bcd00188a2',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85a2b49e-1fdd-4501-a38d-c6762397a253',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f426554f-dbe4-49ce-863f-777f5907160b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6839 | Testing loss: 0.6688 | Training AUC: 0.5463 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6566 | Testing loss: 0.6394 | Training AUC: 0.4830 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6341 | Testing loss: 0.6189 | Training AUC: 0.5779 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6154 | Testing loss: 0.5984 | Training AUC: 0.3945 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6063 | Testing loss: 0.5902 | Training AUC: 0.4635 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5996 | Testing loss: 0.5872 | Training AUC: 0.4399 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.5977 | Testing loss: 0.5852 | Training AUC: 0.3693 | Testing AUC: 0.5000\n",
      "==============="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(se, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test_loss, test_auc \u001b[38;5;241m=\u001b[39m testing(model, optimizer, criterion, test_dataloader)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/sox.py:44\u001b[0m, in \u001b[0;36mSoXBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoX backend does not support loading from file-like objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an alternative backend that does support loading from file-like objects, e.g. FFmpeg.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d33e-739f-435e-8358-db9d0d71b7ae",
   "metadata": {},
   "source": [
    "## + augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee9526e-f18f-4e6f-b348-9b2988e985b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8593fd-f385-47d0-be61-0ee4a6d985b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.augmentations import augment, masking\n",
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42183722-f673-446c-bed3-ee3fa1f68a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, clipping=True, training=True):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.clipping = clipping\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        #\n",
    "        if self.training:\n",
    "            waveform = augment(waveform, sample_rate, self.clipping)\n",
    "        spectrogram = get_spectrogram(waveform, sample_rate, 'lfcc')\n",
    "        if self.training:\n",
    "            spectrogram = masking(spectrogram)\n",
    "        #\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903c6f3e-b5df-4622-8c74-071df0b74aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ad7f7e-6cce-43f7-9c4b-150d26491f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test, training=False)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "575fcb76-5759-49e1-851a-dff093851e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 3))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(5, 30))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(150, 16)\n",
    "        self.linear2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shapes = [x.shape]\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(shapes, self.training)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be78317e-5847-4769-a160-f61a8ef43556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7b5302e-4d47-42f2-940a-1ef48f8ca105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '10_lfcc_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523511de-a6b9-48b3-a6af-d353be3a8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm artifacts/10_lfcc_augmented.joblib\n",
    "# !rm artifacts/10_lfcc_augmented.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cb030e9-7ae9-4732-a60d-ded748075498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Model weights are loaded.\n",
      "!Training stats is loaded.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d6c879-b1b4-49c4-8cf2-0afa28b90d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93be02c2a34996a7884b9ea3912d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b3efe7b4-240c-446e-a987-7a8292aa42ee',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32,\n",
       "                    33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "              'xaxis': 'x',\n",
       "              'y': [0.7155143618583679, 0.7020309567451477, 0.6929250359535217,\n",
       "                    0.6659919619560242, 0.6204260587692261, 0.5947222709655762,\n",
       "                    0.5818471908569336, 0.6010429859161377, 0.6034230589866638,\n",
       "                    0.6020016074180603, 0.5909702777862549, 0.5970460176467896,\n",
       "                    0.6030665636062622, 0.5900964736938477, 0.5845590829849243,\n",
       "                    0.6073806285858154, 0.5929161906242371, 0.5875042676925659,\n",
       "                    0.5706263780593872, 0.5999292135238647, 0.5962024331092834,\n",
       "                    0.5458270907402039, 0.5700557231903076, 0.5630186796188354,\n",
       "                    0.5420098900794983, 0.568469226360321, 0.5711281299591064,\n",
       "                    0.5879102945327759, 0.5631874799728394, 0.5650120377540588,\n",
       "                    0.5818240642547607, 0.584400475025177, 0.5267716646194458,\n",
       "                    0.5812244415283203, 0.5563249588012695, 0.5583116412162781,\n",
       "                    0.5768484473228455, 0.5629105567932129, 0.5991555452346802,\n",
       "                    0.5715504884719849, 0.5609728097915649, 0.5721636414527893,\n",
       "                    0.540745735168457, 0.5926806926727295, 0.5619200468063354,\n",
       "                    0.5767629742622375, 0.5371383428573608, 0.5618376731872559,\n",
       "                    0.5323904752731323, 0.5277367234230042, 0.5323807001113892,\n",
       "                    0.5498682856559753, 0.5507616400718689, 0.5702688097953796,\n",
       "                    0.5747177004814148, 0.518559992313385, 0.53840571641922,\n",
       "                    0.5749330520629883, 0.5425488948822021, 0.576366662979126,\n",
       "                    0.5410009622573853, 0.5793970823287964],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e8ece632-29a3-4e9b-b665-3bb9347d84c9',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32,\n",
       "                    33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "              'xaxis': 'x',\n",
       "              'y': [0.7094320058822632, 0.6954540014266968, 0.6854718327522278,\n",
       "                    0.6045499444007874, 0.5831113457679749, 0.5793699026107788,\n",
       "                    0.5806203484535217, 0.5767478346824646, 0.5850032567977905,\n",
       "                    0.5757434368133545, 0.5776927471160889, 0.5765049457550049,\n",
       "                    0.5775865912437439, 0.5824776887893677, 0.5810623168945312,\n",
       "                    0.5780958533287048, 0.5779980421066284, 0.5782978534698486,\n",
       "                    0.5812418460845947, 0.5824556350708008, 0.5820028781890869,\n",
       "                    0.5890565514564514, 0.586500346660614, 0.5944640636444092,\n",
       "                    0.6172090172767639, 0.6054785847663879, 0.6023952960968018,\n",
       "                    0.5790939927101135, 0.5814288258552551, 0.5846251845359802,\n",
       "                    0.5800288915634155, 0.5808779001235962, 0.5929356217384338,\n",
       "                    0.5852564573287964, 0.5990303754806519, 0.5847533941268921,\n",
       "                    0.5842624306678772, 0.5916842222213745, 0.5855017900466919,\n",
       "                    0.5860536098480225, 0.5870012640953064, 0.5887246131896973,\n",
       "                    0.5915116667747498, 0.5899198055267334, 0.5912697911262512,\n",
       "                    0.5897819995880127, 0.6036713719367981, 0.5941009521484375,\n",
       "                    0.6036236882209778, 0.6107836961746216, 0.6040323972702026,\n",
       "                    0.6210739612579346, 0.6029641628265381, 0.611666202545166,\n",
       "                    0.6129645705223083, 0.6302565932273865, 0.6157154440879822,\n",
       "                    0.6323500275611877, 0.6046464443206787, 0.6191445589065552,\n",
       "                    0.6058549284934998, 0.633849024772644],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cee6a69a-014f-4512-989b-8353b9ef0c7b',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32,\n",
       "                    33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [0.40665584415584416, 0.525974025974026, 0.49269480519480524,\n",
       "                    0.474025974025974, 0.46266233766233766, 0.547077922077922,\n",
       "                    0.6258116883116882, 0.5251623376623377, 0.5137987012987013,\n",
       "                    0.5219155844155844, 0.5949675324675325, 0.5462662337662337,\n",
       "                    0.5827922077922079, 0.5689935064935066, 0.588474025974026,\n",
       "                    0.48457792207792205, 0.551948051948052, 0.5974025974025974,\n",
       "                    0.6201298701298701, 0.5170454545454546, 0.5698051948051948,\n",
       "                    0.689935064935065, 0.6461038961038962, 0.6469155844155845,\n",
       "                    0.7069805194805194, 0.6209415584415584, 0.601461038961039,\n",
       "                    0.5900974025974026, 0.672077922077922, 0.637987012987013,\n",
       "                    0.5641233766233766, 0.6160714285714286, 0.7288961038961039,\n",
       "                    0.6444805194805194, 0.663961038961039, 0.6696428571428571,\n",
       "                    0.622564935064935, 0.650974025974026, 0.6152597402597403,\n",
       "                    0.6501623376623377, 0.6233766233766234, 0.6314935064935064,\n",
       "                    0.7126623376623377, 0.5836038961038962, 0.6412337662337662,\n",
       "                    0.6217532467532467, 0.7232142857142857, 0.7045454545454546,\n",
       "                    0.7110389610389611, 0.7467532467532468, 0.7443181818181819,\n",
       "                    0.6785714285714286, 0.7159090909090909, 0.7037337662337662,\n",
       "                    0.6347402597402598, 0.7232142857142857, 0.7004870129870129,\n",
       "                    0.648538961038961, 0.663961038961039, 0.5892857142857143,\n",
       "                    0.6688311688311688, 0.6209415584415585],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '780ed033-63e1-46d4-95cb-76a8fb078625',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32,\n",
       "                    33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "                    49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [0.4135338345864662, 0.4887218045112782, 0.41353383458646614,\n",
       "                    0.4586466165413534, 0.5338345864661654, 0.5413533834586466,\n",
       "                    0.5413533834586466, 0.518796992481203, 0.5112781954887218,\n",
       "                    0.5112781954887218, 0.5037593984962406, 0.5037593984962406,\n",
       "                    0.5037593984962406, 0.4962406015037594, 0.4887218045112782,\n",
       "                    0.481203007518797, 0.481203007518797, 0.4736842105263158,\n",
       "                    0.4661654135338346, 0.443609022556391, 0.4736842105263158,\n",
       "                    0.4586466165413534, 0.4511278195488722, 0.4360902255639098,\n",
       "                    0.44360902255639095, 0.443609022556391, 0.4285714285714286,\n",
       "                    0.4736842105263158, 0.4736842105263158, 0.4661654135338346,\n",
       "                    0.4586466165413534, 0.4661654135338346, 0.4661654135338346,\n",
       "                    0.4586466165413534, 0.45864661654135336, 0.45864661654135336,\n",
       "                    0.45864661654135336, 0.45112781954887216, 0.4661654135338346,\n",
       "                    0.45112781954887216, 0.4360902255639098, 0.443609022556391,\n",
       "                    0.44360902255639095, 0.44360902255639095, 0.44360902255639095,\n",
       "                    0.44360902255639095, 0.45112781954887216, 0.44360902255639095,\n",
       "                    0.45112781954887216, 0.45112781954887216, 0.44360902255639095,\n",
       "                    0.45112781954887216, 0.43609022556390975, 0.43609022556390975,\n",
       "                    0.45112781954887216, 0.45112781954887216, 0.44360902255639095,\n",
       "                    0.44360902255639095, 0.43609022556390975, 0.44360902255639095,\n",
       "                    0.42857142857142855, 0.44360902255639095],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1382f0-3481-4729-aa05-81cc3c8de128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============"
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats, filename)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
