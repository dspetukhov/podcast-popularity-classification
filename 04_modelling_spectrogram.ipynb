{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903aac58-edab-4517-beb7-9d1b63fd4ec0",
   "metadata": {},
   "source": [
    "**Model training in three ways:**\n",
    "\n",
    "- using images obtained with `Spectrogram` in `03_preprocessing_spectrogram.ipynb`\n",
    "- using spectrograms transformed by `Spectrogram` on the fly\n",
    "- using spectrograms transformed by `Spectrogram` on the fly with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ebc71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T07:52:20.075814Z",
     "start_time": "2024-03-17T07:52:13.517889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "#\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "#\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ConvertImageDtype\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53825dce-2bd1-425f-b04f-339a61d7430d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "2.3.0+cu121\n",
      "0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1aa607c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.048903Z",
     "start_time": "2024-01-07T09:39:43.045946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_path = 'data/raw/'\n",
    "data_path = 'data/spectrogram/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc893f9-4806-4e31-bbad-8187909d66cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9771b003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.895828Z",
     "start_time": "2024-01-07T09:39:43.699453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = yaml.safe_load(open('labels.yaml'))[2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de3b0d9-8bbd-4110-bade-aa843d8de608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = zip(*labels.items())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4130ef6d-d8f8-45d4-aa12-fd8f9d34aaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.train()\n",
    "    for X, Y in dataloader:\n",
    "        X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "        #\n",
    "        output = model(X)\n",
    "        loss = criterion(output.view(1), Y)\n",
    "        #\n",
    "        losses.append(loss.item())\n",
    "        y_true.append(Y.item())\n",
    "        y_score.append(torch.sigmoid(output).item())\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)\n",
    "\n",
    "\n",
    "def testing(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "            #\n",
    "            output = model(X)\n",
    "            loss = criterion(output.view(1), Y)\n",
    "            #\n",
    "            losses.append(loss.item())\n",
    "            y_true.append(Y.item())\n",
    "            y_score.append(torch.sigmoid(output).item())\n",
    "    #\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e3ccb",
   "metadata": {},
   "source": [
    "# Modelling using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d155c4-6487-404d-8ecc-3520e29783f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e5562e-7440-44b6-8418-ad87747370ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1121af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.cid = ConvertImageDtype(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        image = read_image(f'{data_path}/{episode}.png')\n",
    "        return self.cid(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0458835e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409bad50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324496c0-4ba0-496f-8474-142cbb8d4f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(6, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(12, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(12, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(18, 9)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(64, 16))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(4096, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        print('=' if self.training else '-', end='')\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c12eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbef7242-695b-442a-8ae5-a6437bc54af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '04_spectrogram_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7767851-cb54-4048-b11e-640c6cba4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm artifacts/04_spectrogram_images.joblib\n",
    "# !rm artifacts/04_spectrogram_images.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db1ed50-2f25-461f-b04f-5dc6827f3750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Model weights are loaded.\n",
      "!Training stats is loaded.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b1d817-b5d5-4d1e-8bb0-be84cf3b52f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7730a31a0044299be2f4b5074285a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e78b1fee-d0b5-4d2f-bcea-9ea16762ed88',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
       "              'xaxis': 'x',\n",
       "              'y': [0.6473167538642883, 0.6175066232681274, 0.6200255751609802,\n",
       "                    0.6232159733772278, 0.6205547451972961, 0.6200083494186401,\n",
       "                    0.6181317567825317, 0.607863187789917, 0.5915827751159668,\n",
       "                    0.6265431046485901, 0.61553555727005, 0.6012495756149292,\n",
       "                    0.5751613974571228, 0.6118099093437195, 0.7005868554115295,\n",
       "                    0.6693742871284485, 0.6453839540481567, 0.6137458086013794,\n",
       "                    0.6054977178573608, 0.5997354984283447, 0.5949848294258118,\n",
       "                    0.5906602144241333, 0.6048416495323181, 0.5971688032150269,\n",
       "                    0.5927016139030457, 0.6005866527557373, 0.5969004034996033,\n",
       "                    0.596187174320221, 0.58925861120224, 0.5992842316627502,\n",
       "                    0.5992122292518616, 0.5948143601417542, 0.5999152064323425],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bbcc48ce-fdaa-497b-90fe-1e7724f6dc7b',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
       "              'xaxis': 'x',\n",
       "              'y': [0.5830642580986023, 0.5831242203712463, 0.5827106833457947,\n",
       "                    0.5890671610832214, 0.5893698334693909, 0.5833410620689392,\n",
       "                    0.596373438835144, 0.5828778147697449, 0.5830436944961548,\n",
       "                    0.5833300352096558, 0.6087188720703125, 0.5865549445152283,\n",
       "                    0.5848279595375061, 0.5830994844436646, 0.6796766519546509,\n",
       "                    0.6518463492393494, 0.62175053358078, 0.6025418639183044,\n",
       "                    0.5914005041122437, 0.5872987508773804, 0.5853005051612854,\n",
       "                    0.5839985609054565, 0.5843196511268616, 0.5837816596031189,\n",
       "                    0.5833215713500977, 0.5832362771034241, 0.5833384990692139,\n",
       "                    0.5830131769180298, 0.5827986001968384, 0.5829050540924072,\n",
       "                    0.5832497477531433, 0.5829074382781982, 0.5831369757652283],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '208d9b4a-9aff-4d44-95f0-3d2bd0660a60',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [0.42613636363636365, 0.3806818181818182, 0.41720779220779214,\n",
       "                    0.3717532467532467, 0.400974025974026, 0.4699675324675325,\n",
       "                    0.4797077922077922, 0.48295454545454547, 0.5657467532467532,\n",
       "                    0.42126623376623373, 0.4650974025974026, 0.5056818181818181,\n",
       "                    0.6323051948051948, 0.4683441558441558, 0.4715909090909091,\n",
       "                    0.5064935064935066, 0.40665584415584416, 0.5560064935064934,\n",
       "                    0.4650974025974026, 0.5113636363636364, 0.5487012987012987,\n",
       "                    0.5941558441558441, 0.3936688311688311, 0.48538961038961037,\n",
       "                    0.5527597402597403, 0.44805194805194803, 0.5016233766233766,\n",
       "                    0.525974025974026, 0.5949675324675324, 0.49756493506493515,\n",
       "                    0.4261363636363636, 0.5746753246753247, 0.4472402597402597],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a5e27d4c-57b9-46e8-8a87-4676514bc8ec',\n",
       "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [0.5263157894736843, 0.849624060150376, 0.8646616541353385,\n",
       "                    0.12030075187969927, 0.2406015037593985, 0.7293233082706767,\n",
       "                    0.39473684210526316, 0.5451127819548872, 0.09774436090225566,\n",
       "                    0.17293233082706772, 0.40225563909774437, 0.868421052631579,\n",
       "                    0.10150375939849626, 0.8984962406015038, 0.5789473684210527,\n",
       "                    0.48872180451127817, 0.5526315789473684, 0.5526315789473684,\n",
       "                    0.575187969924812, 0.5526315789473684, 0.5526315789473684,\n",
       "                    0.5526315789473684, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c137a9-37e8-4ebf-a878-5d640d106514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================"
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats, filename)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c8157-7ab9-4970-ad55-2f941d85349d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling `as is`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "467333f7-40e4-4e4e-b799-54a0a55b6bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bfc3ee3-d6d9-4801-9295-898f5822d4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ca6a35-bd61-437b-b66d-6438e2fad0d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        #\n",
    "        return get_spectrogram(waveform.mean(dim=0), sample_rate), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0dbd68-6737-4dc1-a49b-fd38127b72e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ff78e2-ab51-4167-ba7b-a13ae54dafbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3e2b10a-ebce-40b0-8c06-0c44ea498a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(6, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(12, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(12, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(18, 9)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(64, 16))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(1024, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('.', end='')\n",
    "        shapes = [x.shape]\n",
    "        # print()\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        print(shapes, self.training)\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6d51325-4dec-43e8-bf38-bcb6daeeb5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "975906ab-b7d6-4963-b7f6-7eea79da2334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 22051, 380]), torch.Size([1, 3674, 126]), torch.Size([1, 305, 20])] True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 22051, 6836]), torch.Size([1, 3674, 2278]), torch.Size([1, 305, 378])] True\n",
      "[torch.Size([1, 22051, 9316]), torch.Size([1, 3674, 3104]), torch.Size([1, 305, 516])] True\n",
      "[torch.Size([1, 22051, 376]), torch.Size([1, 3674, 124]), torch.Size([1, 305, 19])] True\n",
      "[torch.Size([1, 22051, 811]), torch.Size([1, 3674, 269]), torch.Size([1, 305, 44])] True\n",
      "[torch.Size([1, 22051, 10663]), torch.Size([1, 3674, 3553]), torch.Size([1, 305, 591])] True\n",
      "[torch.Size([1, 22051, 10717]), torch.Size([1, 3674, 3571]), torch.Size([1, 305, 594])] True\n",
      "[torch.Size([1, 22051, 462]), torch.Size([1, 3674, 153]), torch.Size([1, 305, 24])] True\n",
      "[torch.Size([1, 22051, 576]), torch.Size([1, 3674, 191]), torch.Size([1, 305, 31])] True\n",
      "[torch.Size([1, 22051, 8935]), torch.Size([1, 3674, 2977]), torch.Size([1, 305, 495])] True\n",
      "[torch.Size([1, 24001, 571]), torch.Size([1, 3999, 189]), torch.Size([1, 332, 30])] True\n",
      "[torch.Size([1, 22051, 473]), torch.Size([1, 3674, 157]), torch.Size([1, 305, 25])] True\n",
      "[torch.Size([1, 22051, 9596]), torch.Size([1, 3674, 3198]), torch.Size([1, 305, 532])] True\n",
      "[torch.Size([1, 22051, 8593]), torch.Size([1, 3674, 2863]), torch.Size([1, 305, 476])] True\n",
      "[torch.Size([1, 24001, 702]), torch.Size([1, 3999, 233]), torch.Size([1, 332, 38])] True\n",
      "[torch.Size([1, 22051, 8820]), torch.Size([1, 3674, 2939]), torch.Size([1, 305, 489])] True\n",
      "[torch.Size([1, 22051, 6606]), torch.Size([1, 3674, 2201]), torch.Size([1, 305, 366])] True\n",
      "[torch.Size([1, 22051, 7814]), torch.Size([1, 3674, 2604]), torch.Size([1, 305, 433])] True\n",
      "[torch.Size([1, 22051, 690]), torch.Size([1, 3674, 229]), torch.Size([1, 305, 37])] True\n",
      "[torch.Size([1, 22051, 7519]), torch.Size([1, 3674, 2505]), torch.Size([1, 305, 416])] True\n",
      "[torch.Size([1, 22051, 8783]), torch.Size([1, 3674, 2927]), torch.Size([1, 305, 487])] True\n",
      "[torch.Size([1, 22051, 813]), torch.Size([1, 3674, 270]), torch.Size([1, 305, 44])] True\n",
      "[torch.Size([1, 22051, 389]), torch.Size([1, 3674, 129]), torch.Size([1, 305, 20])] True\n",
      "[torch.Size([1, 22051, 10032]), torch.Size([1, 3674, 3343]), torch.Size([1, 305, 556])] True\n",
      "[torch.Size([1, 24001, 643]), torch.Size([1, 3999, 213]), torch.Size([1, 332, 34])] True\n",
      "[torch.Size([1, 24001, 535]), torch.Size([1, 3999, 177]), torch.Size([1, 332, 28])] True\n",
      "[torch.Size([1, 22051, 2304]), torch.Size([1, 3674, 767]), torch.Size([1, 305, 127])] True\n",
      "[torch.Size([1, 22051, 9786]), torch.Size([1, 3674, 3261]), torch.Size([1, 305, 542])] True\n",
      "[torch.Size([1, 22051, 9611]), torch.Size([1, 3674, 3203]), torch.Size([1, 305, 533])] True\n",
      "[torch.Size([1, 22051, 9916]), torch.Size([1, 3674, 3304]), torch.Size([1, 305, 549])] True\n",
      "[torch.Size([1, 22051, 391]), torch.Size([1, 3674, 129]), torch.Size([1, 305, 20])] True\n",
      "[torch.Size([1, 24001, 289]), torch.Size([1, 3999, 95]), torch.Size([1, 332, 15])] True\n",
      "[torch.Size([1, 22051, 6260]), torch.Size([1, 3674, 2086]), torch.Size([1, 305, 346])] True\n",
      "[torch.Size([1, 24001, 435]), torch.Size([1, 3999, 144]), torch.Size([1, 332, 23])] True\n",
      "[torch.Size([1, 22051, 4136]), torch.Size([1, 3674, 1378]), torch.Size([1, 305, 228])] True\n",
      "[torch.Size([1, 22051, 369]), torch.Size([1, 3674, 122]), torch.Size([1, 305, 19])] True\n",
      "[torch.Size([1, 24001, 434]), torch.Size([1, 3999, 144]), torch.Size([1, 332, 23])] True\n",
      "[torch.Size([1, 22051, 9065]), torch.Size([1, 3674, 3021]), torch.Size([1, 305, 502])] True\n",
      "[torch.Size([1, 24001, 6416]), torch.Size([1, 3999, 2138]), torch.Size([1, 332, 355])] True\n",
      "[torch.Size([1, 22051, 439]), torch.Size([1, 3674, 145]), torch.Size([1, 305, 23])] True\n",
      "[torch.Size([1, 22051, 4021]), torch.Size([1, 3674, 1339]), torch.Size([1, 305, 222])] True\n",
      "[torch.Size([1, 22051, 10327]), torch.Size([1, 3674, 3441]), torch.Size([1, 305, 572])] True\n",
      "[torch.Size([1, 24001, 379]), torch.Size([1, 3999, 125]), torch.Size([1, 332, 20])] True\n",
      "[torch.Size([1, 22051, 7932]), torch.Size([1, 3674, 2643]), torch.Size([1, 305, 439])] True\n",
      "[torch.Size([1, 24001, 5436]), torch.Size([1, 3999, 1811]), torch.Size([1, 332, 301])] True\n",
      "[torch.Size([1, 22051, 1385]), torch.Size([1, 3674, 461]), torch.Size([1, 305, 76])] True\n",
      "[torch.Size([1, 22051, 5888]), torch.Size([1, 3674, 1962]), torch.Size([1, 305, 326])] True\n",
      "[torch.Size([1, 22051, 673]), torch.Size([1, 3674, 223]), torch.Size([1, 305, 36])] True\n",
      "[torch.Size([1, 24001, 9798]), torch.Size([1, 3999, 3265]), torch.Size([1, 332, 543])] True\n",
      "[torch.Size([1, 22051, 7674]), torch.Size([1, 3674, 2557]), torch.Size([1, 305, 425])] True\n",
      "[torch.Size([1, 24001, 853]), torch.Size([1, 3999, 283]), torch.Size([1, 332, 46])] True\n",
      "[torch.Size([1, 22051, 10179]), torch.Size([1, 3674, 3392]), torch.Size([1, 305, 564])] True\n",
      "[torch.Size([1, 24001, 6543]), torch.Size([1, 3999, 2180]), torch.Size([1, 332, 362])] True\n",
      "[torch.Size([1, 22051, 7198]), torch.Size([1, 3674, 2398]), torch.Size([1, 305, 398])] True\n",
      "[torch.Size([1, 22051, 8442]), torch.Size([1, 3674, 2813]), torch.Size([1, 305, 468])] True\n",
      "[torch.Size([1, 22051, 558]), torch.Size([1, 3674, 185]), torch.Size([1, 305, 30])] True\n",
      "[torch.Size([1, 22051, 649]), torch.Size([1, 3674, 215]), torch.Size([1, 305, 35])] True\n",
      "[torch.Size([1, 22051, 633]), torch.Size([1, 3674, 210]), torch.Size([1, 305, 34])] True\n",
      "[torch.Size([1, 22051, 376]), torch.Size([1, 3674, 124]), torch.Size([1, 305, 19])] True\n",
      "[torch.Size([1, 22051, 6391]), torch.Size([1, 3674, 2129]), torch.Size([1, 305, 354])] True\n",
      "[torch.Size([1, 22051, 402]), torch.Size([1, 3674, 133]), torch.Size([1, 305, 21])] True\n",
      "[torch.Size([1, 22051, 299]), torch.Size([1, 3674, 99]), torch.Size([1, 305, 15])] True\n",
      "[torch.Size([1, 22051, 623]), torch.Size([1, 3674, 207]), torch.Size([1, 305, 33])] True\n",
      "[torch.Size([1, 22051, 662]), torch.Size([1, 3674, 220]), torch.Size([1, 305, 35])] True\n",
      "[torch.Size([1, 22051, 8592]), torch.Size([1, 3674, 2863]), torch.Size([1, 305, 476])] True\n",
      "[torch.Size([1, 22051, 424]), torch.Size([1, 3674, 140]), torch.Size([1, 305, 22])] True\n",
      "[torch.Size([1, 24001, 669]), torch.Size([1, 3999, 222]), torch.Size([1, 332, 36])] True\n",
      "[torch.Size([1, 24001, 419]), torch.Size([1, 3999, 139]), torch.Size([1, 332, 22])] True\n",
      "[torch.Size([1, 22051, 595]), torch.Size([1, 3674, 197]), torch.Size([1, 305, 32])] True\n",
      "[torch.Size([1, 22051, 14776]), torch.Size([1, 3674, 4924]), torch.Size([1, 305, 819])] True\n",
      "[torch.Size([1, 22051, 12836]), torch.Size([1, 3674, 4278]), torch.Size([1, 305, 712])] True\n",
      "[torch.Size([1, 22051, 6710]), torch.Size([1, 3674, 2236]), torch.Size([1, 305, 371])] True\n",
      "[torch.Size([1, 22051, 9530]), torch.Size([1, 3674, 3176]), torch.Size([1, 305, 528])] True\n",
      "[torch.Size([1, 22051, 6570]), torch.Size([1, 3674, 2189]), torch.Size([1, 305, 364])] True\n",
      "[torch.Size([1, 24001, 8889]), torch.Size([1, 3999, 2962]), torch.Size([1, 332, 492])] True\n",
      "[torch.Size([1, 22051, 5070]), torch.Size([1, 3674, 1689]), torch.Size([1, 305, 280])] True\n",
      "[torch.Size([1, 22051, 8887]), torch.Size([1, 3674, 2961]), torch.Size([1, 305, 492])] True\n",
      "[torch.Size([1, 24001, 819]), torch.Size([1, 3999, 272]), torch.Size([1, 332, 44])] True\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d79d0-16a0-4570-a46d-d4eda9bd38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019e2982-65f6-4d2f-b2fe-4f3a6e8cdf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '04_spectrogram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65af4d7-a2a5-4631-8ad3-440111cc8240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm artifacts/04_spectrogram.joblib\n",
    "# !rm artifacts/04_spectrogram.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9face793-f709-4a49-a1a7-e8e68df32306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00b9f53-20cf-4b24-a127-440f33a78386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315e6def7b0458aa96f3b99664c3a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd75c8fd7-84f7-4255-93c1-d86de94902d8',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a67c2412-66fe-4a2c-9ea1-250839a17e70',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1f4a53af-c8a9-433e-9b94-19bcd00188a2',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85a2b49e-1fdd-4501-a38d-c6762397a253',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f426554f-dbe4-49ce-863f-777f5907160b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6839 | Testing loss: 0.6688 | Training AUC: 0.5463 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6566 | Testing loss: 0.6394 | Training AUC: 0.4830 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6341 | Testing loss: 0.6189 | Training AUC: 0.5779 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6154 | Testing loss: 0.5984 | Training AUC: 0.3945 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6063 | Testing loss: 0.5902 | Training AUC: 0.4635 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5996 | Testing loss: 0.5872 | Training AUC: 0.4399 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.5977 | Testing loss: 0.5852 | Training AUC: 0.3693 | Testing AUC: 0.5000\n",
      "==============="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(se, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test_loss, test_auc \u001b[38;5;241m=\u001b[39m testing(model, optimizer, criterion, test_dataloader)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/sox.py:44\u001b[0m, in \u001b[0;36mSoXBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoX backend does not support loading from file-like objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an alternative backend that does support loading from file-like objects, e.g. FFmpeg.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d33e-739f-435e-8358-db9d0d71b7ae",
   "metadata": {},
   "source": [
    "## + augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee9526e-f18f-4e6f-b348-9b2988e985b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc8593fd-f385-47d0-be61-0ee4a6d985b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.augmentations import augment, masking\n",
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42183722-f673-446c-bed3-ee3fa1f68a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, clipping=True, training=True):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.clipping = clipping\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        #\n",
    "        if self.training:\n",
    "            waveform = augment(waveform, sample_rate, self.clipping)\n",
    "        spectrogram = get_spectrogram(waveform, sample_rate)\n",
    "        if self.training:\n",
    "            spectrogram = masking(spectrogram)\n",
    "        #\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "903c6f3e-b5df-4622-8c74-071df0b74aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17ad7f7e-6cce-43f7-9c4b-150d26491f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test, training=False)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f728ccf1-a2c8-4daa-854d-65b3bb0f74c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(6, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(12, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(12, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(18, 9)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(64, 8))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(256, 64)\n",
    "        self.linear2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # \n",
    "        shapes = [x.shape]\n",
    "        # print()\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        print(shapes, self.training)\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be78317e-5847-4769-a160-f61a8ef43556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80384fff-2dc6-4fcc-b3c4-6a3ca89e754b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 22051, 227]), torch.Size([1, 3674, 75]), torch.Size([1, 305, 11])] True\n",
      "[torch.Size([1, 22051, 227]), torch.Size([1, 3674, 75]), torch.Size([1, 305, 11])] True\n",
      "[torch.Size([1, 22051, 227]), torch.Size([1, 3674, 75]), torch.Size([1, 305, 11])] True\n",
      "[torch.Size([1, 22051, 227]), torch.Size([1, 3674, 75]), torch.Size([1, 305, 11])] True\n",
      "[torch.Size([1, 24001, 209]), torch.Size([1, 3999, 69]), torch.Size([1, 332, 10])] True\n",
      "[torch.Size([1, 22051, 227]), torch.Size([1, 3674, 75]), torch.Size([1, 305, 11])] True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m get_spectrogram(waveform, sample_rate)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m---> 23\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m \u001b[43mmasking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram, label\n",
      "File \u001b[0;32m/data/podcast/utils/augmentations.py:72\u001b[0m, in \u001b[0;36mmasking\u001b[0;34m(spectrogram)\u001b[0m\n\u001b[1;32m     70\u001b[0m tm \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mTimeMasking(time_mask_param\u001b[38;5;241m=\u001b[39m(spectrogram\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m40\u001b[39m)))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m)):\n\u001b[0;32m---> 72\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:1204\u001b[0m, in \u001b[0;36m_AxisMasking.forward\u001b[0;34m(self, specgram, mask_value)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmask_along_axis_iid(\n\u001b[1;32m   1201\u001b[0m         specgram, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_param, mask_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m+\u001b[39m specgram\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\n\u001b[1;32m   1202\u001b[0m     )\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecgram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspecgram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/functional/functional.py:949\u001b[0m, in \u001b[0;36mmask_along_axis\u001b[0;34m(specgram, mask_param, mask_value, axis, p)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_end \u001b[38;5;241m-\u001b[39m mask_start \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mask_param:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns to be masked should be less than mask_param\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 949\u001b[0m specgram \u001b[38;5;241m=\u001b[39m \u001b[43mspecgram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# unpack batch\u001b[39;00m\n\u001b[1;32m    952\u001b[0m specgram \u001b[38;5;241m=\u001b[39m specgram\u001b[38;5;241m.\u001b[39mreshape(shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m specgram\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe102c-42ae-46ad-8b1b-4c8d5cd9934b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b5302e-4d47-42f2-940a-1ef48f8ca105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '04_spectrogram_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523511de-a6b9-48b3-a6af-d353be3a8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm artifacts/04_spectrogram_augmented.joblib\n",
    "# !rm artifacts/04_spectrogram_augmented.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cb030e9-7ae9-4732-a60d-ded748075498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d6c879-b1b4-49c4-8cf2-0afa28b90d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d885a3edeb2463fbf3ce4dbf3f5746b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'edc7e996-62e5-4959-af8c-b5de8b11f1bd',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd1c68424-6ef3-4598-bb1a-22cce02b78dd',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1d23d7c9-f8b0-4b99-a41d-226bbbd67aa1',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a7b9bac9-615a-4277-a978-c87dbc1fd40e',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b1382f0-3481-4729-aa05-81cc3c8de128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6839 | Testing loss: 0.6688 | Training AUC: 0.5463 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6566 | Testing loss: 0.6394 | Training AUC: 0.4830 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6341 | Testing loss: 0.6189 | Training AUC: 0.5779 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6154 | Testing loss: 0.5984 | Training AUC: 0.3945 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6063 | Testing loss: 0.5902 | Training AUC: 0.4635 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5996 | Testing loss: 0.5872 | Training AUC: 0.4399 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.5977 | Testing loss: 0.5852 | Training AUC: 0.3693 | Testing AUC: 0.5000\n",
      "==============="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(se, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test_loss, test_auc \u001b[38;5;241m=\u001b[39m testing(model, optimizer, criterion, test_dataloader)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/sox.py:44\u001b[0m, in \u001b[0;36mSoXBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoX backend does not support loading from file-like objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an alternative backend that does support loading from file-like objects, e.g. FFmpeg.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
