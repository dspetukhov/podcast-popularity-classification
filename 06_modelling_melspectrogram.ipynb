{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee3ecb6-40ea-46d7-9568-fcb2fabd92e0",
   "metadata": {},
   "source": [
    "**Model training in three ways:**\n",
    "\n",
    "- using images obtained with `MelSpectrogram` in `05_preprocessing_melspectrogram.ipynb`\n",
    "- using spectrograms transformed by `MelSpectrogram` on the fly\n",
    "- using spectrograms transformed by `MelSpectrogram` on the fly with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ebc71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T07:52:20.075814Z",
     "start_time": "2024-03-17T07:52:13.517889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "#\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "#\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ConvertImageDtype\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53825dce-2bd1-425f-b04f-339a61d7430d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "2.3.0+cu121\n",
      "0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1aa607c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.048903Z",
     "start_time": "2024-01-07T09:39:43.045946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_path = 'data/raw/'\n",
    "data_path = 'data/melspectrogram/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc893f9-4806-4e31-bbad-8187909d66cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9771b003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.895828Z",
     "start_time": "2024-01-07T09:39:43.699453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = yaml.safe_load(open('labels.yaml'))[2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de3b0d9-8bbd-4110-bade-aa843d8de608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = zip(*labels.items())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4130ef6d-d8f8-45d4-aa12-fd8f9d34aaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.train()\n",
    "    for X, Y in dataloader:\n",
    "        X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "        #\n",
    "        output = model(X)\n",
    "        loss = criterion(output.view(1), Y)\n",
    "        #\n",
    "        losses.append(loss.item())\n",
    "        y_true.append(Y.item())\n",
    "        y_score.append(torch.sigmoid(output).item())\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)\n",
    "\n",
    "\n",
    "def testing(model, optimizer, criterion, dataloader):\n",
    "    losses, y_true, y_score = [], [], []\n",
    "    #\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device, dtype=torch.float32)\n",
    "            #\n",
    "            output = model(X)\n",
    "            loss = criterion(output.view(1), Y)\n",
    "            #\n",
    "            losses.append(loss.item())\n",
    "            y_true.append(Y.item())\n",
    "            y_score.append(torch.sigmoid(output).item())\n",
    "    #\n",
    "    return torch.tensor(losses).mean(), roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e3ccb",
   "metadata": {},
   "source": [
    "# Modelling using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d155c4-6487-404d-8ecc-3520e29783f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e5562e-7440-44b6-8418-ad87747370ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1121af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.cid = ConvertImageDtype(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        image = read_image(f'{data_path}/{episode}.png')\n",
    "        return self.cid(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0458835e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409bad50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324496c0-4ba0-496f-8474-142cbb8d4f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(2, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 4))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(3, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(5, 10)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(20, 10))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(800, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shapes = [x.shape]\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(shapes)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        print('=' if self.training else '-', end='')\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c12eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbef7242-695b-442a-8ae5-a6437bc54af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '06_melspectrogram_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7767851-cb54-4048-b11e-640c6cba4332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm artifacts/06_melspectrogram_images.joblib\n",
    "# !rm artifacts/06_melspectrogram_images.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db1ed50-2f25-461f-b04f-5dc6827f3750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b1d817-b5d5-4d1e-8bb0-be84cf3b52f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf9426f5e4b407f8db0f4f19278d57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5741494c-e585-4db5-bd47-85f491c2077d',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': '136444da-bbca-466d-bebd-0c348bd5a0a8',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '092e8c72-749b-4bbd-af4b-a2999532f781',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7f7949d4-6c58-4325-8c39-66db4616218b',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c137a9-37e8-4ebf-a878-5d640d106514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6968 | Testing loss: 0.6805 | Training AUC: 0.5836 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6627 | Testing loss: 0.6361 | Training AUC: 0.3977 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6326 | Testing loss: 0.6161 | Training AUC: 0.4935 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6171 | Testing loss: 0.6009 | Training AUC: 0.4537 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6044 | Testing loss: 0.5889 | Training AUC: 0.4984 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5959 | Testing loss: 0.5855 | Training AUC: 0.5300 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.6092 | Testing loss: 0.5850 | Training AUC: 0.3157 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 7 | Training loss: 0.5974 | Testing loss: 0.5848 | Training AUC: 0.4846 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 8 | Training loss: 0.6075 | Testing loss: 0.5835 | Training AUC: 0.3336 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 9 | Training loss: 0.5887 | Testing loss: 0.5833 | Training AUC: 0.5917 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 10 | Training loss: 0.5933 | Testing loss: 0.5832 | Training AUC: 0.5455 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 11 | Training loss: 0.5952 | Testing loss: 0.5835 | Training AUC: 0.5268 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 12 | Training loss: 0.5974 | Testing loss: 0.5833 | Training AUC: 0.4959 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 13 | Training loss: 0.5951 | Testing loss: 0.5829 | Training AUC: 0.5260 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 14 | Training loss: 0.5826 | Testing loss: 0.5827 | Training AUC: 0.6802 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 15 | Training loss: 0.5985 | Testing loss: 0.5827 | Training AUC: 0.4683 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 16 | Training loss: 0.5911 | Testing loss: 0.5827 | Training AUC: 0.5706 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 17 | Training loss: 0.6070 | Testing loss: 0.5829 | Training AUC: 0.3904 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 18 | Training loss: 0.5928 | Testing loss: 0.5831 | Training AUC: 0.5130 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 19 | Training loss: 0.6079 | Testing loss: 0.5833 | Training AUC: 0.3198 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 20 | Training loss: 0.6034 | Testing loss: 0.5831 | Training AUC: 0.3994 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 21 | Training loss: 0.5950 | Testing loss: 0.5832 | Training AUC: 0.5235 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 22 | Training loss: 0.6035 | Testing loss: 0.5829 | Training AUC: 0.3888 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 23 | Training loss: 0.6017 | Testing loss: 0.5836 | Training AUC: 0.4058 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 24 | Training loss: 0.6034 | Testing loss: 0.5835 | Training AUC: 0.4294 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 25 | Training loss: 0.5992 | Testing loss: 0.5834 | Training AUC: 0.4367 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 26 | Training loss: 0.5942 | Testing loss: 0.5834 | Training AUC: 0.5317 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 27 | Training loss: 0.6004 | Testing loss: 0.5834 | Training AUC: 0.4407 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 28 | Training loss: 0.6022 | Testing loss: 0.5834 | Training AUC: 0.4188 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 29 | Training loss: 0.5946 | Testing loss: 0.5829 | Training AUC: 0.5325 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 30 | Training loss: 0.6048 | Testing loss: 0.5831 | Training AUC: 0.3799 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 31 | Training loss: 0.6007 | Testing loss: 0.5833 | Training AUC: 0.4545 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 32 | Training loss: 0.6003 | Testing loss: 0.5831 | Training AUC: 0.4359 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 33 | Training loss: 0.6008 | Testing loss: 0.5841 | Training AUC: 0.4107 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 34 | Training loss: 0.5938 | Testing loss: 0.5834 | Training AUC: 0.5138 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 35 | Training loss: 0.5960 | Testing loss: 0.5827 | Training AUC: 0.5162 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 36 | Training loss: 0.5949 | Testing loss: 0.5829 | Training AUC: 0.5170 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 37 | Training loss: 0.5998 | Testing loss: 0.5834 | Training AUC: 0.4756 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 38 | Training loss: 0.5973 | Testing loss: 0.5829 | Training AUC: 0.5106 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 39 | Training loss: 0.5890 | Testing loss: 0.5829 | Training AUC: 0.5901 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 40 | Training loss: 0.5969 | Testing loss: 0.5828 | Training AUC: 0.4838 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 41 | Training loss: 0.5931 | Testing loss: 0.5828 | Training AUC: 0.5503 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 42 | Training loss: 0.5983 | Testing loss: 0.5829 | Training AUC: 0.4562 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 43 | Training loss: 0.5958 | Testing loss: 0.5834 | Training AUC: 0.5016 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 44 | Training loss: 0.5911 | Testing loss: 0.5828 | Training AUC: 0.5722 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 45 | Training loss: 0.5996 | Testing loss: 0.5831 | Training AUC: 0.4513 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 46 | Training loss: 0.5908 | Testing loss: 0.5827 | Training AUC: 0.5641 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 47 | Training loss: 0.5972 | Testing loss: 0.5830 | Training AUC: 0.4756 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 48 | Training loss: 0.5884 | Testing loss: 0.5829 | Training AUC: 0.6234 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 49 | Training loss: 0.5975 | Testing loss: 0.5829 | Training AUC: 0.4992 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 50 | Training loss: 0.5864 | Testing loss: 0.5828 | Training AUC: 0.6161 | Testing AUC: 0.5000\n",
      "!Model weights were saved.\n",
      "==============================================================================--------------------------\n",
      "Epoch: 51 | Training loss: 0.5955 | Testing loss: 0.5829 | Training AUC: 0.5065 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 52 | Training loss: 0.6011 | Testing loss: 0.5829 | Training AUC: 0.4164 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 53 | Training loss: 0.5938 | Testing loss: 0.5830 | Training AUC: 0.4692 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 54 | Training loss: 0.5986 | Testing loss: 0.5828 | Training AUC: 0.4627 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 55 | Training loss: 0.5972 | Testing loss: 0.5829 | Training AUC: 0.4675 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 56 | Training loss: 0.6046 | Testing loss: 0.5829 | Training AUC: 0.3977 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 57 | Training loss: 0.6011 | Testing loss: 0.5829 | Training AUC: 0.4115 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 58 | Training loss: 0.6023 | Testing loss: 0.5836 | Training AUC: 0.4391 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 59 | Training loss: 0.6077 | Testing loss: 0.5841 | Training AUC: 0.3482 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 60 | Training loss: 0.5919 | Testing loss: 0.5833 | Training AUC: 0.5617 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 61 | Training loss: 0.6037 | Testing loss: 0.5831 | Training AUC: 0.4229 | Testing AUC: 0.5000\n",
      "======================================"
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c8157-7ab9-4970-ad55-2f941d85349d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling `as is`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "467333f7-40e4-4e4e-b799-54a0a55b6bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bfc3ee3-d6d9-4801-9295-898f5822d4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ca6a35-bd61-437b-b66d-6438e2fad0d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        #\n",
    "        return get_spectrogram(waveform.mean(dim=0), sample_rate, 'melspectrogram'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d0dbd68-6737-4dc1-a49b-fd38127b72e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ff78e2-ab51-4167-ba7b-a13ae54dafbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3e2b10a-ebce-40b0-8c06-0c44ea498a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 4))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 6)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 6))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 10)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(20, 10))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(200, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('.', end='')\n",
    "        shapes = [x.shape]\n",
    "        # print()\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(shapes, self.training)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d51325-4dec-43e8-bf38-bcb6daeeb5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "975906ab-b7d6-4963-b7f6-7eea79da2334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 4136]), torch.Size([1, 63, 1033]), torch.Size([1, 20, 171])] True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 7814]), torch.Size([1, 63, 1952]), torch.Size([1, 20, 324])] True\n",
      "[torch.Size([1, 128, 419]), torch.Size([1, 63, 104]), torch.Size([1, 20, 16])] True\n",
      "[torch.Size([1, 128, 402]), torch.Size([1, 63, 99]), torch.Size([1, 20, 15])] True\n",
      "[torch.Size([1, 128, 8889]), torch.Size([1, 63, 2221]), torch.Size([1, 20, 369])] True\n",
      "[torch.Size([1, 128, 12836]), torch.Size([1, 63, 3208]), torch.Size([1, 20, 533])] True\n",
      "[torch.Size([1, 128, 8935]), torch.Size([1, 63, 2233]), torch.Size([1, 20, 371])] True\n",
      "[torch.Size([1, 128, 6543]), torch.Size([1, 63, 1635]), torch.Size([1, 20, 271])] True\n",
      "[torch.Size([1, 128, 8887]), torch.Size([1, 63, 2221]), torch.Size([1, 20, 369])] True\n",
      "[torch.Size([1, 128, 434]), torch.Size([1, 63, 107]), torch.Size([1, 20, 17])] True\n",
      "[torch.Size([1, 128, 439]), torch.Size([1, 63, 109]), torch.Size([1, 20, 17])] True\n",
      "[torch.Size([1, 128, 576]), torch.Size([1, 63, 143]), torch.Size([1, 20, 23])] True\n",
      "[torch.Size([1, 128, 10327]), torch.Size([1, 63, 2581]), torch.Size([1, 20, 429])] True\n",
      "[torch.Size([1, 128, 10032]), torch.Size([1, 63, 2507]), torch.Size([1, 20, 417])] True\n",
      "[torch.Size([1, 128, 7674]), torch.Size([1, 63, 1917]), torch.Size([1, 20, 318])] True\n",
      "[torch.Size([1, 128, 643]), torch.Size([1, 63, 160]), torch.Size([1, 20, 25])] True\n",
      "[torch.Size([1, 128, 595]), torch.Size([1, 63, 148]), torch.Size([1, 20, 23])] True\n",
      "[torch.Size([1, 128, 6710]), torch.Size([1, 63, 1676]), torch.Size([1, 20, 278])] True\n",
      "[torch.Size([1, 128, 9798]), torch.Size([1, 63, 2448]), torch.Size([1, 20, 407])] True\n",
      "[torch.Size([1, 128, 690]), torch.Size([1, 63, 171]), torch.Size([1, 20, 27])] True\n",
      "[torch.Size([1, 128, 389]), torch.Size([1, 63, 96]), torch.Size([1, 20, 15])] True\n",
      "[torch.Size([1, 128, 4021]), torch.Size([1, 63, 1004]), torch.Size([1, 20, 166])] True\n",
      "[torch.Size([1, 128, 7198]), torch.Size([1, 63, 1798]), torch.Size([1, 20, 298])] True\n",
      "[torch.Size([1, 128, 535]), torch.Size([1, 63, 133]), torch.Size([1, 20, 21])] True\n",
      "[torch.Size([1, 128, 649]), torch.Size([1, 63, 161]), torch.Size([1, 20, 26])] True\n",
      "[torch.Size([1, 128, 813]), torch.Size([1, 63, 202]), torch.Size([1, 20, 32])] True\n",
      "[torch.Size([1, 128, 10663]), torch.Size([1, 63, 2665]), torch.Size([1, 20, 443])] True\n",
      "[torch.Size([1, 128, 6391]), torch.Size([1, 63, 1597]), torch.Size([1, 20, 265])] True\n",
      "[torch.Size([1, 128, 7932]), torch.Size([1, 63, 1982]), torch.Size([1, 20, 329])] True\n",
      "[torch.Size([1, 128, 424]), torch.Size([1, 63, 105]), torch.Size([1, 20, 16])] True\n",
      "[torch.Size([1, 128, 435]), torch.Size([1, 63, 108]), torch.Size([1, 20, 17])] True\n",
      "[torch.Size([1, 128, 853]), torch.Size([1, 63, 212]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 662]), torch.Size([1, 63, 164]), torch.Size([1, 20, 26])] True\n",
      "[torch.Size([1, 128, 669]), torch.Size([1, 63, 166]), torch.Size([1, 20, 26])] True\n",
      "[torch.Size([1, 128, 10179]), torch.Size([1, 63, 2544]), torch.Size([1, 20, 423])] True\n",
      "[torch.Size([1, 128, 673]), torch.Size([1, 63, 167]), torch.Size([1, 20, 27])] True\n",
      "[torch.Size([1, 128, 811]), torch.Size([1, 63, 202]), torch.Size([1, 20, 32])] True\n",
      "[torch.Size([1, 128, 391]), torch.Size([1, 63, 97]), torch.Size([1, 20, 15])] True\n",
      "[torch.Size([1, 128, 6260]), torch.Size([1, 63, 1564]), torch.Size([1, 20, 259])] True\n",
      "[torch.Size([1, 128, 8442]), torch.Size([1, 63, 2109]), torch.Size([1, 20, 350])] True\n",
      "[torch.Size([1, 128, 623]), torch.Size([1, 63, 155]), torch.Size([1, 20, 25])] True\n",
      "[torch.Size([1, 128, 14776]), torch.Size([1, 63, 3693]), torch.Size([1, 20, 614])] True\n",
      "[torch.Size([1, 128, 5436]), torch.Size([1, 63, 1358]), torch.Size([1, 20, 225])] True\n",
      "[torch.Size([1, 128, 380]), torch.Size([1, 63, 94]), torch.Size([1, 20, 14])] True\n",
      "[torch.Size([1, 128, 299]), torch.Size([1, 63, 74]), torch.Size([1, 20, 11])] True\n",
      "[torch.Size([1, 128, 1385]), torch.Size([1, 63, 345]), torch.Size([1, 20, 56])] True\n",
      "[torch.Size([1, 128, 9596]), torch.Size([1, 63, 2398]), torch.Size([1, 20, 398])] True\n",
      "[torch.Size([1, 128, 6570]), torch.Size([1, 63, 1641]), torch.Size([1, 20, 272])] True\n",
      "[torch.Size([1, 128, 8820]), torch.Size([1, 63, 2204]), torch.Size([1, 20, 366])] True\n",
      "[torch.Size([1, 128, 558]), torch.Size([1, 63, 138]), torch.Size([1, 20, 22])] True\n",
      "[torch.Size([1, 128, 289]), torch.Size([1, 63, 71]), torch.Size([1, 20, 11])] True\n",
      "[torch.Size([1, 128, 819]), torch.Size([1, 63, 204]), torch.Size([1, 20, 33])] True\n",
      "[torch.Size([1, 128, 10717]), torch.Size([1, 63, 2678]), torch.Size([1, 20, 445])] True\n",
      "[torch.Size([1, 128, 9530]), torch.Size([1, 63, 2381]), torch.Size([1, 20, 396])] True\n",
      "[torch.Size([1, 128, 8593]), torch.Size([1, 63, 2147]), torch.Size([1, 20, 357])] True\n",
      "[torch.Size([1, 128, 702]), torch.Size([1, 63, 174]), torch.Size([1, 20, 28])] True\n",
      "[torch.Size([1, 128, 369]), torch.Size([1, 63, 91]), torch.Size([1, 20, 14])] True\n",
      "[torch.Size([1, 128, 633]), torch.Size([1, 63, 157]), torch.Size([1, 20, 25])] True\n",
      "[torch.Size([1, 128, 9611]), torch.Size([1, 63, 2402]), torch.Size([1, 20, 399])] True\n",
      "[torch.Size([1, 128, 6606]), torch.Size([1, 63, 1650]), torch.Size([1, 20, 274])] True\n",
      "[torch.Size([1, 128, 376]), torch.Size([1, 63, 93]), torch.Size([1, 20, 14])] True\n",
      "[torch.Size([1, 128, 5070]), torch.Size([1, 63, 1266]), torch.Size([1, 20, 210])] True\n",
      "[torch.Size([1, 128, 571]), torch.Size([1, 63, 142]), torch.Size([1, 20, 22])] True\n",
      "[torch.Size([1, 128, 462]), torch.Size([1, 63, 114]), torch.Size([1, 20, 18])] True\n",
      "[torch.Size([1, 128, 9916]), torch.Size([1, 63, 2478]), torch.Size([1, 20, 412])] True\n",
      "[torch.Size([1, 128, 8783]), torch.Size([1, 63, 2195]), torch.Size([1, 20, 365])] True\n",
      "[torch.Size([1, 128, 9786]), torch.Size([1, 63, 2445]), torch.Size([1, 20, 406])] True\n",
      "[torch.Size([1, 128, 5888]), torch.Size([1, 63, 1471]), torch.Size([1, 20, 244])] True\n",
      "[torch.Size([1, 128, 6416]), torch.Size([1, 63, 1603]), torch.Size([1, 20, 266])] True\n",
      "[torch.Size([1, 128, 9316]), torch.Size([1, 63, 2328]), torch.Size([1, 20, 387])] True\n",
      "[torch.Size([1, 128, 7519]), torch.Size([1, 63, 1879]), torch.Size([1, 20, 312])] True\n",
      "[torch.Size([1, 128, 2304]), torch.Size([1, 63, 575]), torch.Size([1, 20, 95])] True\n",
      "[torch.Size([1, 128, 9065]), torch.Size([1, 63, 2265]), torch.Size([1, 20, 376])] True\n",
      "[torch.Size([1, 128, 379]), torch.Size([1, 63, 94]), torch.Size([1, 20, 14])] True\n",
      "[torch.Size([1, 128, 473]), torch.Size([1, 63, 117]), torch.Size([1, 20, 18])] True\n",
      "[torch.Size([1, 128, 6836]), torch.Size([1, 63, 1708]), torch.Size([1, 20, 283])] True\n",
      "[torch.Size([1, 128, 376]), torch.Size([1, 63, 93]), torch.Size([1, 20, 14])] True\n",
      "[torch.Size([1, 128, 8592]), torch.Size([1, 63, 2147]), torch.Size([1, 20, 357])] True\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019e2982-65f6-4d2f-b2fe-4f3a6e8cdf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '06_melspectrogram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65af4d7-a2a5-4631-8ad3-440111cc8240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm artifacts/06_melspectrogram.joblib\n",
    "# !rm artifacts/06_melspectrogram.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9face793-f709-4a49-a1a7-e8e68df32306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00b9f53-20cf-4b24-a127-440f33a78386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315e6def7b0458aa96f3b99664c3a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd75c8fd7-84f7-4255-93c1-d86de94902d8',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a67c2412-66fe-4a2c-9ea1-250839a17e70',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1f4a53af-c8a9-433e-9b94-19bcd00188a2',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85a2b49e-1fdd-4501-a38d-c6762397a253',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f426554f-dbe4-49ce-863f-777f5907160b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6839 | Testing loss: 0.6688 | Training AUC: 0.5463 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6566 | Testing loss: 0.6394 | Training AUC: 0.4830 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6341 | Testing loss: 0.6189 | Training AUC: 0.5779 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6154 | Testing loss: 0.5984 | Training AUC: 0.3945 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6063 | Testing loss: 0.5902 | Training AUC: 0.4635 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5996 | Testing loss: 0.5872 | Training AUC: 0.4399 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.5977 | Testing loss: 0.5852 | Training AUC: 0.3693 | Testing AUC: 0.5000\n",
      "==============="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(se, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test_loss, test_auc \u001b[38;5;241m=\u001b[39m testing(model, optimizer, criterion, test_dataloader)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/sox.py:44\u001b[0m, in \u001b[0;36mSoXBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoX backend does not support loading from file-like objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an alternative backend that does support loading from file-like objects, e.g. FFmpeg.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d33e-739f-435e-8358-db9d0d71b7ae",
   "metadata": {},
   "source": [
    "## + augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ee9526e-f18f-4e6f-b348-9b2988e985b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc8593fd-f385-47d0-be61-0ee4a6d985b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.augmentations import augment, masking\n",
    "from utils.spectrograms import get_spectrogram\n",
    "from utils.miscellaneous import update_stats\n",
    "from utils.plot import get_figure, update_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42183722-f673-446c-bed3-ee3fa1f68a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, clipping=True, training=True):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.clipping = clipping\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        #\n",
    "        waveform, sample_rate = torchaudio.load(f'{raw_path}/{episode}.mp3')\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        #\n",
    "        if self.training:\n",
    "            waveform = augment(waveform, sample_rate, self.clipping)\n",
    "        spectrogram = get_spectrogram(waveform, sample_rate, 'melspectrogram')\n",
    "        if self.training:\n",
    "            spectrogram = masking(spectrogram)\n",
    "        #\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "903c6f3e-b5df-4622-8c74-071df0b74aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17ad7f7e-6cce-43f7-9c4b-150d26491f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test, training=False)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "575fcb76-5759-49e1-851a-dff093851e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T10:15:41.917197Z",
     "start_time": "2024-03-10T10:15:41.903943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 3))\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(20, 32))\n",
    "        )\n",
    "        #\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(640, 64)\n",
    "        self.linear2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('.', end='')\n",
    "        shapes = [x.shape]\n",
    "        # print()\n",
    "        x = self.layer1(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        shapes.append(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(shapes, self.training)\n",
    "        #\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print('=' if self.training else '-', end='')\n",
    "        #\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be78317e-5847-4769-a160-f61a8ef43556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74ecdd32-73a8-480a-a983-1a9458b9142d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 209]), torch.Size([1, 63, 104]), torch.Size([1, 20, 34])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n",
      "[torch.Size([1, 128, 227]), torch.Size([1, 63, 113]), torch.Size([1, 20, 37])] True\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652fc6c-cdf3-4a5e-9df7-b9dc891ef5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b5302e-4d47-42f2-940a-1ef48f8ca105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '06_melspectrogram_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523511de-a6b9-48b3-a6af-d353be3a8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm artifacts/06_melspectrogram_augmented.joblib\n",
    "# !rm artifacts/06_melspectrogram_augmented.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cb030e9-7ae9-4732-a60d-ded748075498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'artifacts/{filename}.pt'):\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'artifacts/{filename}.pt')\n",
    "    )\n",
    "    print('!Model weights are loaded.')\n",
    "    \n",
    "if os.path.exists(f'artifacts/{filename}.joblib'):\n",
    "    stats = joblib.load(f'artifacts/{filename}.joblib')\n",
    "    print('!Training stats is loaded.')\n",
    "else:\n",
    "    stats = {\n",
    "        'epoch': [],\n",
    "        'training_loss': [],\n",
    "        'testing_loss': [],\n",
    "        'training_auc': [],\n",
    "        'testing_auc': [],\n",
    "    }\n",
    "    \n",
    "se = stats['epoch'][-1] if stats['epoch'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d6c879-b1b4-49c4-8cf2-0afa28b90d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d885a3edeb2463fbf3ce4dbf3f5746b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Training',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'edc7e996-62e5-4959-af8c-b5de8b11f1bd',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Testing',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd1c68424-6ef3-4598-bb1a-22cce02b78dd',\n",
       "              'x': [],\n",
       "              'xaxis': 'x',\n",
       "              'y': [],\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'black', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1d23d7c9-f8b0-4b99-a41d-226bbbd67aa1',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'},\n",
       "             {'line': {'color': 'red', 'dash': 'dash', 'width': 0.5},\n",
       "              'marker': {'color': 'white', 'line': {'color': 'red', 'width': 1}, 'size': 6},\n",
       "              'mode': 'lines+markers',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a7b9bac9-615a-4277-a978-c87dbc1fd40e',\n",
       "              'x': [],\n",
       "              'xaxis': 'x2',\n",
       "              'y': [],\n",
       "              'yaxis': 'y2'}],\n",
       "    'layout': {'font': {'family': 'Arial', 'size': 12},\n",
       "               'height': 500,\n",
       "               'plot_bgcolor': 'white',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 0.45],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Epoch'}},\n",
       "               'xaxis2': {'anchor': 'y2',\n",
       "                          'domain': [0.55, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'gridcolor': 'lightgrey',\n",
       "                         'griddash': 'dot',\n",
       "                         'gridwidth': 0.1,\n",
       "                         'linecolor': 'black',\n",
       "                         'mirror': True,\n",
       "                         'showgrid': True,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Loss'}},\n",
       "               'yaxis2': {'anchor': 'x2',\n",
       "                          'domain': [0.0, 1.0],\n",
       "                          'gridcolor': 'lightgrey',\n",
       "                          'griddash': 'dot',\n",
       "                          'gridwidth': 0.1,\n",
       "                          'linecolor': 'black',\n",
       "                          'mirror': True,\n",
       "                          'showgrid': True,\n",
       "                          'showline': True,\n",
       "                          'title': {'text': 'AUC ROC'}}}\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = get_figure(stats)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b1382f0-3481-4729-aa05-81cc3c8de128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning:\n",
      "\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================--------------------------\n",
      "Epoch: 0 | Training loss: 0.6839 | Testing loss: 0.6688 | Training AUC: 0.5463 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 1 | Training loss: 0.6566 | Testing loss: 0.6394 | Training AUC: 0.4830 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 2 | Training loss: 0.6341 | Testing loss: 0.6189 | Training AUC: 0.5779 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 3 | Training loss: 0.6154 | Testing loss: 0.5984 | Training AUC: 0.3945 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 4 | Training loss: 0.6063 | Testing loss: 0.5902 | Training AUC: 0.4635 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 5 | Training loss: 0.5996 | Testing loss: 0.5872 | Training AUC: 0.4399 | Testing AUC: 0.5000\n",
      "==============================================================================--------------------------\n",
      "Epoch: 6 | Training loss: 0.5977 | Testing loss: 0.5852 | Training AUC: 0.3693 | Testing AUC: 0.5000\n",
      "==============="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(se, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test_loss, test_auc \u001b[38;5;241m=\u001b[39m testing(model, optimizer, criterion, test_dataloader)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mPodcast.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m episode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchaudio/_backend/sox.py:44\u001b[0m, in \u001b[0;36mSoXBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoX backend does not support loading from file-like objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an alternative backend that does support loading from file-like objects, e.g. FFmpeg.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(se, 200):\n",
    "    train_loss, train_auc = training(model, optimizer, criterion, train_dataloader)\n",
    "    test_loss, test_auc = testing(model, optimizer, criterion, test_dataloader)\n",
    "    #\n",
    "    update_stats(stats, epoch, train_loss, test_loss, train_auc, test_auc)\n",
    "    update_figure(figure, stats)\n",
    "    #\n",
    "    joblib.dump(stats, f'artifacts/{filename}.joblib')\n",
    "    if epoch % 5 == 0:\n",
    "        if len(stats['testing_loss']) >= 10:\n",
    "            x0 = torch.tensor(stats['testing_loss'][-10:-5]).mean()\n",
    "            if x0 > torch.tensor(stats['testing_loss'][-5:]).mean():\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f'artifacts/{filename}.pt'\n",
    "                )\n",
    "                print('!Model weights were saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
