{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f179957",
   "metadata": {},
   "source": [
    "- https://learn.microsoft.com/en-us/training/modules/intro-audio-classification-pytorch/1-introduction\n",
    "\n",
    "- https://medium.com/@lelandroberts97/musical-genre-classification-with-convolutional-neural-networks-ff04f9601a74\n",
    "\n",
    "- https://towardsdatascience.com/audio-classification-with-deep-learning-in-python-cf752b22ba07\n",
    "\n",
    "- https://pytorch.org/audio/main/index.html\n",
    "\n",
    "- https://www.scaler.com/topics/pytorch/torchaudio-in-pytorch/\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Spectrogram\n",
    "\n",
    "- https://towardsdatascience.com/audio-deep-learning-made-simple-part-2-why-mel-spectrograms-perform-better-aad889a93505\n",
    "\n",
    "- https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ebc71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:41.386977Z",
     "start_time": "2024-01-07T09:39:39.320092Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#\n",
    "import torchaudio\n",
    "# import torchaudio.transforms as T\n",
    "# import torchaudio.functional as F\n",
    "#\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ConvertImageDtype\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "#\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f79dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:41.392939Z",
     "start_time": "2024-01-07T09:39:41.389322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1aa607c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.048903Z",
     "start_time": "2024-01-07T09:39:43.045946Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_file = 'data.yaml'\n",
    "data_path = 'data/processed_spectrograms_with_standardization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9771b003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:43.895828Z",
     "start_time": "2024-01-07T09:39:43.699453Z"
    }
   },
   "outputs": [],
   "source": [
    "cache = yaml.safe_load(open(cache_file, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499958a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:44.271445Z",
     "start_time": "2024-01-07T09:39:44.260501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(el, float(cache[el]['stats'] >= 38.225)) for el in cache if cache[el]['year'] == 2022]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5987a531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:44.807918Z",
     "start_time": "2024-01-07T09:39:44.802823Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = zip(*data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1121af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:45.388382Z",
     "start_time": "2024-01-07T09:39:45.383137Z"
    }
   },
   "outputs": [],
   "source": [
    "class Podcast(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.cid = ConvertImageDtype(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        episode = self.x[idx]\n",
    "        image = read_image(f'{data_path}/{episode}.png')\n",
    "        return self.cid(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0458835e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:46.519333Z",
     "start_time": "2024-01-07T09:39:46.515826Z"
    }
   },
   "outputs": [],
   "source": [
    "train = Podcast(X_train, y_train)\n",
    "train_dataloader = DataLoader(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409bad50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:39:47.385464Z",
     "start_time": "2024-01-07T09:39:47.381841Z"
    }
   },
   "outputs": [],
   "source": [
    "test = Podcast(X_test, y_test)\n",
    "test_dataloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e3ccb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a964003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:01:22.946354Z",
     "start_time": "2024-01-07T10:01:22.931665Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=16, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=32, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(256, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(x.shape)\n",
    "        #    \n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "#         x = self.dropout(x, training=self.training)\n",
    "        print(x.shape, self.training)\n",
    "        #\n",
    "        return self.linear2(x)  \n",
    "\n",
    "model = CNNet().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bda3faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:02.929832Z",
     "start_time": "2024-01-07T09:56:02.924948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(8, 8), stride=(2, 2))\n",
       "    (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(16, 16), stride=(2, 2))\n",
       "    (1): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(32, 32), stride=(2, 2))\n",
       "    (1): AvgPool2d(kernel_size=16, stride=16, padding=0)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c12eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T09:56:03.622408Z",
     "start_time": "2024-01-07T09:56:03.618260Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0428b84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T12:49:18.027476Z",
     "start_time": "2024-01-07T11:32:35.844052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6915, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6948, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6915, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0031], grad_fn=<ViewBackward0>) tensor([1.], dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6915, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0032], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0033], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6915, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) True\n",
      "tensor([-0.0030], grad_fn=<ViewBackward0>) tensor([0.], dtype=torch.float64)\n",
      "tensor(0.6916, dtype=torch.float64,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_score = []\n",
    "y_true = []\n",
    "\n",
    "model.train()\n",
    "for idx, (X, y) in enumerate(train_dataloader):\n",
    "\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output[0], y)\n",
    "    #\n",
    "    print(output.view(1), y)\n",
    "    print(loss)\n",
    "    y_score.append(loss.item())\n",
    "    y_true.append(y.item())\n",
    "    #\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e92c13d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T12:49:38.811876Z",
     "start_time": "2024-01-07T12:49:38.759941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cc18dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T13:00:32.909213Z",
     "start_time": "2024-01-07T12:50:40.178057Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.691569983959198 tensor([[-0.0032]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916375160217285 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.694721382111311 tensor([[-0.0031]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.694707565009594 tensor([[-0.0031]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.691636860370636 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.691636860370636 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916038393974304 tensor([[-0.0031]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6915795803070068 tensor([[-0.0031]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916411519050598 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916378140449524 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916369199752808 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6947391517460346 tensor([[-0.0032]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916362047195435 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6947310101240873 tensor([[-0.0032]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916285157203674 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6915491819381714 tensor([[-0.0032]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6947604827582836 tensor([[-0.0032]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6946998462080956 tensor([[-0.0031]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916360259056091 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6915158033370972 tensor([[-0.0033]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6915425658226013 tensor([[-0.0032]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916382908821106 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6947044394910336 tensor([[-0.0031]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916280388832092 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916072368621826 tensor([[-0.0031]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916366219520569 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916365623474121 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6915267705917358 tensor([[-0.0032]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.691586971282959 tensor([[-0.0031]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.694711048156023 tensor([[-0.0031]]) tensor([1.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916376948356628 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n",
      ".torch.Size([1, 8, 2755, 1846])\n",
      "torch.Size([1, 16, 171, 114])\n",
      "torch.Size([1, 32, 4, 2])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 32]) False\n",
      "0.6916371583938599 tensor([[-0.0030]]) tensor([0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_score = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        print('.', end='')\n",
    "        #\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "        #\n",
    "        y_score.append(\n",
    "            criterion(output[0], y).item()\n",
    "        )\n",
    "        y_true.append(y.item())\n",
    "        #\n",
    "        print(y_score[-1], output, y)\n",
    "#         test_loss += cost(pred, Y).item()\n",
    "#         correct += (pred.argmax(1)==Y).type(torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "734cdc41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T11:30:46.178003Z",
     "start_time": "2024-01-07T11:30:46.172545Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0db9b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T13:03:15.455237Z",
     "start_time": "2024-01-07T13:03:15.447204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88423b35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T13:03:21.285300Z",
     "start_time": "2024-01-07T13:03:21.278345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868c2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac2797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179d9212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T09:28:31.100382Z",
     "start_time": "2023-12-31T09:28:31.095403Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output.view(1), Y.type(torch.FloatTensor))\n",
    "        #\n",
    "        print(output.view(1), Y)\n",
    "        print(loss)\n",
    "        #\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         print(loss)\n",
    "#         if batch % 100 == 0:\n",
    "#             current = batch * len(X)\n",
    "#             print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7758b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "class_map = ['no', 'yes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c853b319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T09:53:59.480707Z",
     "start_time": "2023-12-31T09:28:43.476754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "580 torch.Size([4, 22051, 14776])\n",
      "torch.Size([1, 128, 340, 226])\n",
      "torch.Size([1, 9835520])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x9835520 and 739840x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test(test_dataloader, model)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m), Y)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m), Y\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor))\n",
      "File \u001b[0;32m~/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mCNNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m         x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         x = nn.functional.dropout(x, training=self.training)\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x9835520 and 739840x64)"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, criterion, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c37c33",
   "metadata": {},
   "source": [
    "- https://wandb.ai/ayush-thakur/dl-question-bank/reports/How-to-Handle-Images-of-Different-Sizes-in-a-Convolutional-Neural-Network--VmlldzoyMDk3NzQ\n",
    "\n",
    "- https://blog.paperspace.com/global-pooling-in-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c43850ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:27:12.866542Z",
     "start_time": "2024-01-01T15:27:12.863628Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9047474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:44:14.206152Z",
     "start_time": "2024-01-01T15:44:14.199891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03358662964523873\n",
      "0 0.1 []\n",
      "0\n",
      "0.3405022703178888\n",
      "0 0.1 [0]\n",
      "0.1 0.5 [0]\n",
      "1\n",
      "0.12637400239713015\n",
      "0 0.1 [0, 1]\n",
      "0.1 0.5 [0, 1]\n",
      "1\n",
      "0.7956959568389843\n",
      "0 0.1 [0, 1, 1]\n",
      "0.1 0.5 [0, 1, 1]\n",
      "0.5 0.7 [0, 1, 1]\n",
      "0.7 1.0 [0, 1, 1]\n",
      "3\n",
      "0.021017163545093864\n",
      "0 0.1 [0, 1, 1, 3]\n",
      "0\n",
      "0.2790766399824478\n",
      "0 0.1 [0, 1, 1, 3, 0]\n",
      "0.1 0.5 [0, 1, 1, 3, 0]\n",
      "1\n",
      "0.19695354310223356\n",
      "0 0.1 [0, 1, 1, 3, 0, 1]\n",
      "0.1 0.5 [0, 1, 1, 3, 0, 1]\n",
      "1\n",
      "0.1389510492928656\n",
      "0 0.1 [0, 1, 1, 3, 0, 1, 1]\n",
      "0.1 0.5 [0, 1, 1, 3, 0, 1, 1]\n",
      "1\n",
      "0.3078099601608696\n",
      "0 0.1 [0, 1, 1, 3, 0, 1, 1, 1]\n",
      "0.1 0.5 [0, 1, 1, 3, 0, 1, 1, 1]\n",
      "1\n",
      "0.5177160995077268\n",
      "0 0.1 [0, 1, 1, 3, 0, 1, 1, 1, 1]\n",
      "0.1 0.5 [0, 1, 1, 3, 0, 1, 1, 1, 1]\n",
      "0.5 0.7 [0, 1, 1, 3, 0, 1, 1, 1, 1]\n",
      "2\n",
      "[0, 0.1, 0.5, 0.7, 1.0] [0, 1, 1, 3, 0, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "probas = [0.1, 0.4, 0.2, 0.3]\n",
    "size = 10\n",
    "result = []\n",
    "\n",
    "res = [0]\n",
    "for p in probas:\n",
    "    res.append(res[-1]+p)\n",
    "        \n",
    "# res\n",
    "for _ in range(size):\n",
    "#     print(random.random())\n",
    "    rr = random.random()\n",
    "    print(rr)\n",
    "    for idx in range(len(res)-1):\n",
    "        print(res[idx], res[idx+1], result)\n",
    "        if rr >= res[idx] and rr < res[idx+1]:\n",
    "            print(idx)\n",
    "            result.append(idx)\n",
    "            break\n",
    "            \n",
    "print(res, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de086073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:26:36.436800Z",
     "start_time": "2024-01-01T15:26:36.431445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "seq = [1, 1, 0, 0, 1, 1]\n",
    "# seq = [1, 1, 0, 0, 1, 1, 1]\n",
    "# seq = [0, 0, 0]\n",
    "# seq = []\n",
    "res = 0\n",
    "tmp = 0\n",
    "for el in seq:\n",
    "    if el == 1:\n",
    "        tmp += 1\n",
    "        res = max(res, tmp)\n",
    "    else:\n",
    "        tmp = 0\n",
    "    \n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f81d1898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T10:18:39.488758Z",
     "start_time": "2023-12-10T10:18:39.484807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(podcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6553f1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T09:49:55.874491Z",
     "start_time": "2023-12-23T09:49:55.638754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 3,\n",
       " 'dow': 'Tuesday',\n",
       " 'month': 'May',\n",
       " 'year': 2022,\n",
       " 'title': 'SDS 571: Collaborative, No-Code Machine Learning',\n",
       " 'duration': 58,\n",
       " 'link': 'https://www.youtube.com/embed/c5LyEtZcxiY',\n",
       " 'stats': 41.5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml.safe_load(open(cache_file, 'r'))[571]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8341e2",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f8d2f",
   "metadata": {},
   "source": [
    "- https://github.com/daisukelab/ml-sound-classifier\n",
    "\n",
    "- https://www.kaggle.com/c/freesound-audio-tagging\n",
    "\n",
    "- https://github.com/daisukelab/sound-clf-pytorch\n",
    "\n",
    "- https://clear.ml/blog/audio-classification-with-pytorchs-ecosystem-tools\n",
    "\n",
    "- https://www.kaggle.com/code/aayush9753/audio-classification-starter-in-pytorch\n",
    "\n",
    "- https://blogs.rstudio.com/ai/posts/2022-10-06-audio-classification-torch/\n",
    "\n",
    "- https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/audio_classifier_tutorial.ipynb\n",
    "\n",
    "- https://bamblebam.medium.com/audio-classification-and-regression-using-pytorch-48db77b3a5ec\n",
    "\n",
    "- https://www.kaggle.com/code/psycheshaman/pytorch-human-speech-classification\n",
    "\n",
    "- https://huggingface.co/docs/transformers/tasks/audio_classification\n",
    "\n",
    "- https://github.com/huggingface/transformers/blob/main/examples/pytorch/audio-classification/README.md\n",
    "\n",
    "- https://music-classification.github.io/tutorial/part3_supervised/tutorial.html\n",
    "\n",
    "- https://medium.com/@mlg.fcu/using-python-to-classify-sounds-a-deep-learning-approach-ef00278bb6ad\n",
    "\n",
    "- https://www.youtube.com/watch?v=TkwXa7Cvfr8&t=1251s\n",
    "\n",
    "- https://www.youtube.com/watch?v=O5xeyoRL95U\n",
    "\n",
    "- https://medium.com/mlearning-ai/music-genre-classification-using-cnn-part-2-classification-ee5400cfbc4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e94dfdfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T10:18:40.295857Z",
     "start_time": "2023-12-10T10:18:40.103429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 torch.Size([4, 22051, 662])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[201, 188, 251,  ..., 255, 255, 255],\n",
       "          [220, 192, 241,  ..., 242, 255, 255],\n",
       "          [213, 193, 234,  ..., 235, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]],\n",
       " \n",
       "         [[201, 188, 251,  ..., 255, 255, 255],\n",
       "          [220, 192, 241,  ..., 242, 255, 255],\n",
       "          [213, 193, 234,  ..., 235, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]],\n",
       " \n",
       "         [[201, 188, 251,  ..., 255, 255, 255],\n",
       "          [220, 192, 241,  ..., 242, 255, 255],\n",
       "          [213, 193, 234,  ..., 235, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]],\n",
       " \n",
       "         [[255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]]], dtype=torch.uint8),\n",
       " 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7ab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d501134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T09:12:16.999223Z",
     "start_time": "2023-12-10T09:12:16.779815Z"
    }
   },
   "outputs": [],
   "source": [
    "cache = yaml.safe_load(open('data.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d23f41b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T09:12:17.782585Z",
     "start_time": "2023-12-10T09:12:17.777625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_dict = {el: cache[el]['stats'] for el in cache if cache[el]['year'] == 2022}\n",
    "len(popularity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8186fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T09:12:18.501126Z",
     "start_time": "2023-12-10T09:12:18.496348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 20.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(popularity_dict.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "919fef5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T09:12:19.388765Z",
     "start_time": "2023-12-10T09:12:19.383669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 48.7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(popularity_dict.items(), key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd8040",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee4f58",
   "metadata": {},
   "source": [
    "- https://speechprocessingbook.aalto.fi/Representations/Melcepstrum.html\n",
    "\n",
    "- https://mmchiou.gitbooks.io/uwsgi/content/tensorflow-speech-recognition-challenge/kernel/speech-representation-and-data-exploration/notebooksrde/visualizationspae.html\n",
    "\n",
    "- https://vtiya.medium.com/mfcc-vs-mel-spectrogram-8f1dc0abbc62\n",
    "\n",
    "- https://ketanhdoshi.github.io/Audio-ASR/\n",
    "\n",
    "- https://towardsdatascience.com/audio-deep-learning-made-simple-part-2-why-mel-spectrograms-perform-better-aad889a93505\n",
    "\n",
    "- https://www-i6.informatik.rwth-aachen.de/publications/download/937/T%7Bu%7DskeZolt%7Ba%7DnGolikPavelSchl%7Bu%7DterRalfNeyHermann--AcousticModelingwithDeepNeuralNetworksUsingRawTimeSignalfor%7BLVCSR%7D--2014.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
